{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgKUWdjynfaY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Remove all the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set env CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Retina display\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "try:\n",
        "    from einops import rearrange\n",
        "except ImportError:\n",
        "    %pip install einops\n",
        "    from einops import rearrange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('dog.jpg'):\n",
        "    print('dog.jpg exists')\n",
        "else:\n",
        "    !wget https://segment-anything.com/assets/gallery/AdobeStock_94274587_welsh_corgi_pembroke_CD.jpg -O dog.jpg\n"
      ],
      "metadata": {
        "id": "6bOdP6hSwHW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "img = torchvision.io.read_image(\"dog.jpg\")\n",
        "\n",
        "scaler_img = preprocessing.MinMaxScaler().fit(img.reshape(-1, 1))\n",
        "scaler_img"
      ],
      "metadata": {
        "id": "StteJJWUwL-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_scaled = scaler_img.transform(img.reshape(-1, 1)).reshape(img.shape)\n",
        "img_scaled = torch.tensor(img_scaled)\n",
        "img_scaled = img_scaled.to(device)"
      ],
      "metadata": {
        "id": "YHHYetPnwgqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop = torchvision.transforms.functional.crop(img_scaled.cpu(), 600, 800, 300, 300)\n",
        "crop.shape"
      ],
      "metadata": {
        "id": "uWtSeQxVwi18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(rearrange(crop, 'c h w -> h w c').cpu().numpy())\n",
        "print(crop.shape)"
      ],
      "metadata": {
        "id": "i2LsKT-4wmBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop = crop.to(device)"
      ],
      "metadata": {
        "id": "LsQgK6i0wnWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels, height, width = crop.shape"
      ],
      "metadata": {
        "id": "DEIdxv9KwzIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB5YBlGqnfab"
      },
      "outputs": [],
      "source": [
        "def create_coordinate_map(img, scale=1):\n",
        "    \"\"\"\n",
        "    img: torch.Tensor of shape (num_channels, height, width)\n",
        "\n",
        "    return: tuple of torch.Tensor of shape (height * width, 2) and torch.Tensor of shape (height * width, num_channels)\n",
        "    \"\"\"\n",
        "\n",
        "    num_channels, height, width = img.shape\n",
        "\n",
        "    # Create a 2D grid of (x,y) coordinates (h, w)\n",
        "    # width values change faster than height values\n",
        "    w_coords = torch.arange(0, width,  1/scale).repeat(int(height*scale), 1)\n",
        "    h_coords = torch.arange(0, height, 1/scale).repeat(int(width*scale), 1).t()\n",
        "    w_coords = w_coords.reshape(-1)\n",
        "    h_coords = h_coords.reshape(-1)\n",
        "\n",
        "    # Combine the x and y coordinates into a single tensor\n",
        "    X = torch.stack([h_coords, w_coords], dim=1).float()\n",
        "\n",
        "    # Move X to GPU if available\n",
        "    X = X.to(device)\n",
        "\n",
        "    # Reshape the image to (h * w, num_channels)\n",
        "    Y = rearrange(img, 'c h w -> (h w) c').float()\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dog_X, dog_Y = create_coordinate_map(crop, scale=1)\n",
        "\n",
        "dog_X.shape, dog_Y.shape"
      ],
      "metadata": {
        "id": "KwsaCir2xBFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler from -1 to 1\n",
        "scaler_X = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit(dog_X.cpu())\n",
        "\n",
        "# Scale the X coordinates\n",
        "dog_X_scaled = scaler_X.transform(dog_X.cpu())\n",
        "\n",
        "# Move the scaled X coordinates to the GPU\n",
        "dog_X_scaled = torch.tensor(dog_X_scaled).to(device)\n",
        "\n",
        "# Set to dtype float32\n",
        "dog_X_scaled = dog_X_scaled.float()"
      ],
      "metadata": {
        "id": "etp7uiNpxEM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuhbJ7agfUkA"
      },
      "outputs": [],
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2JP2wfwnfaf"
      },
      "outputs": [],
      "source": [
        "def train(net, lr, X, Y, epochs, verbose=True, stopping_criteria=0.00001):\n",
        "    \"\"\"\n",
        "    net: torch.nn.Module\n",
        "    lr: float\n",
        "    X: torch.Tensor of shape (num_samples, 2)\n",
        "    Y: torch.Tensor of shape (num_samples, 3)\n",
        "    \"\"\"\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    prev_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(X)\n",
        "\n",
        "        loss = criterion(outputs, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if verbose and epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch} loss: {loss.item():.6f}\")\n",
        "\n",
        "        if prev_loss - loss.item() <= stopping_criteria:\n",
        "            break\n",
        "\n",
        "        prev_loss = loss.item()\n",
        "\n",
        "    return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstructed_and_original_image(gt, original_img, net, X, title=\"\" ):\n",
        "    \"\"\"\n",
        "    net: torch.nn.Module\n",
        "    X: torch.Tensor of shape (num_samples, 2)\n",
        "    Y: torch.Tensor of shape (num_samples, 3)\n",
        "    \"\"\"\n",
        "    num_channels, height, width = original_img.shape\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = net(X)\n",
        "        outputs_reshaped = outputs.reshape(height, width, num_channels)\n",
        "        #outputs = outputs.permute(1, 2, 0)\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1,1])\n",
        "\n",
        "    ax0 = plt.subplot(gs[0])\n",
        "    ax1 = plt.subplot(gs[1])\n",
        "    ax2 = plt.subplot(gs[2])\n",
        "\n",
        "    ax0.imshow(outputs_reshaped.cpu())\n",
        "    ax0.set_title(\"Reconstructed Image\")\n",
        "\n",
        "\n",
        "    ax1.imshow(original_img.cpu().permute(1, 2, 0))\n",
        "    ax1.set_title(\"Original Image\")\n",
        "\n",
        "    ax2.imshow(gt.cpu().permute(1, 2, 0))\n",
        "    ax2.set_title(\"GT Image\")\n",
        "\n",
        "    for a in [ax0, ax1]:\n",
        "        a.axis(\"off\")\n",
        "\n",
        "\n",
        "    fig.suptitle(title, y=0.9)\n",
        "    plt.tight_layout()\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "TH_g1BduxcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rff_features(X, num_features, sigma):\n",
        "    from sklearn.kernel_approximation import RBFSampler\n",
        "    X_numpy = X.cpu().numpy()\n",
        "    rff = RBFSampler(n_components=num_features, gamma=1 / (2 * sigma ** 2))\n",
        "    X_transformed = rff.fit_transform(X_numpy)\n",
        "    return torch.tensor(X_transformed, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "NJxJqpj2xeWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZz3v0zajJ8X"
      },
      "outputs": [],
      "source": [
        "def calculate_rmse(predicted, ground_truth):\n",
        "    rmse = torch.sqrt(F.mse_loss(predicted, ground_truth))\n",
        "    return rmse.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_psnr(predicted, ground_truth, max_val=255):\n",
        "    mse = F.mse_loss(predicted, ground_truth)\n",
        "    psnr = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
        "    return psnr.item()"
      ],
      "metadata": {
        "id": "Rt9fnpu-yA4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYDvfcg4wCx9"
      },
      "outputs": [],
      "source": [
        "p_value = 1\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubJ4ewwwCx-"
      },
      "source": [
        "### 10% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsPLerT5kaZi"
      },
      "outputs": [],
      "source": [
        "p_value = 0.1\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 10% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHXNGjudwCx-"
      },
      "source": [
        "### 20% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98duKjMKwCx_"
      },
      "outputs": [],
      "source": [
        "p_value = 0.2\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "# Remove elements where the mask is False\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 20% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyowzlA-wCx_"
      },
      "source": [
        "### 30% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlIRy8pUwCx_"
      },
      "outputs": [],
      "source": [
        "p_value = 0.3\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 30% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHSdFKzZwCyA"
      },
      "source": [
        "### 40% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iiBkEFHwCyA"
      },
      "outputs": [],
      "source": [
        "p_value = 0.4\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 40% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No2Q2m8IwCyB"
      },
      "source": [
        "### 50% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK8bp_oJwCyB"
      },
      "outputs": [],
      "source": [
        "p_value = 0.5\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 50% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIof-d1TwCyB"
      },
      "source": [
        "### 60% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1_FpstVwCyC"
      },
      "outputs": [],
      "source": [
        "p_value = 0.6\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 60% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQW7sc5FwCyC"
      },
      "source": [
        "### 70% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B-7tLZUwCyC"
      },
      "outputs": [],
      "source": [
        "p_value = 0.7\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 70% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjjBEg21wCyD"
      },
      "source": [
        "### 80% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPbwTSTIwCyD"
      },
      "outputs": [],
      "source": [
        "p_value = 0.8\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 80% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3krViQmSwCyD"
      },
      "source": [
        "### 90% data missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AHcMnRTwCyE"
      },
      "outputs": [],
      "source": [
        "p_value = 0.9\n",
        "mask = torch.rand(height*width) > p_value\n",
        "\n",
        "X_rff = create_rff_features(dog_X_scaled, 37500, 0.008)\n",
        "X_rff = X_rff.to(device)\n",
        "X_rff_mask = X_rff[mask]\n",
        "X_rff.shape, X_rff_mask.shape\n",
        "\n",
        "dog_Y_mask = dog_Y[mask]\n",
        "dog_Y_mask = dog_Y_mask.to(device)\n",
        "dog_Y_mask.shape\n",
        "\n",
        "net = LinearModel(X_rff_mask.shape[1], 3)\n",
        "net.to(device)\n",
        "\n",
        "train(net, 0.005, X_rff_mask, dog_Y_mask, 5000)\n",
        "\n",
        "crop = crop.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "outputs = plot_reconstructed_and_original_image( crop, crop*mask.reshape(300,300), net, X_rff, title=\"Reconstructed Image with RFF Features with 90% data missing\")\n",
        "\n",
        "rmse_value = calculate_rmse(outputs, crop.reshape(height*width, num_channels))\n",
        "psnr_value = calculate_psnr(outputs, crop.reshape(height*width, num_channels))\n",
        "\n",
        "print(f\"RMSE: {rmse_value}\")\n",
        "print(f\"PSNR: {psnr_value}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}